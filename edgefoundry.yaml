model_path: ./models/tinyllama.gguf
runtime: llama_cpp
device: local
